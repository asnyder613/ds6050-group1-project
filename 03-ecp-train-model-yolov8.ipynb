{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "139b6807-2bc9-4481-9a9c-4ea70a1a3d5a"
   },
   "source": [
    "# YOLOv8 Model Training (ECP)\n",
    "**Purpose: Train YOLOv8 model on ECP dataset**</br>\n",
    "**Final Project**</br>\n",
    "**Group 1**</br>\n",
    "**DS6050 Deep Learning**</br>\n",
    "**Fall 2023**</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install wandb -q\n",
    "%pip install ultralytics -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "4d701f3e-eea6-41bd-a5a9-2e23ecbf6de8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path: /scratch/ybt7qf/ds6050-group1-project/datasets/eurocitypersonsdataset\n",
      "train: /scratch/ybt7qf/ds6050-group1-project/datasets/eurocitypersonsdataset/images/train-resize\n",
      "val: /scratch/ybt7qf/ds6050-group1-project/datasets/eurocitypersonsdataset/images/val-resize\n",
      "    \n",
      "nc: 12\n",
      "    \n",
      "names: [\n",
      "    'pedestrian',\n",
      "    'bicycle',\n",
      "    'bicycle-group',\n",
      "    'motorbike-group',\n",
      "    'scooter-group',\n",
      "    'rider+vehicle-group-far-away',\n",
      "    'motorbike',\n",
      "    'wheelchair-group',\n",
      "    'buggy-group',\n",
      "    'person-group-far-away',\n",
      "    'rider',\n",
      "    'tricycle-group'\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "!cat /scratch/ybt7qf/ds6050-group1-project/datasets/eurocitypersonsdataset.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "34f7434f-9407-48c9-9ca4-eebe69f28eb0",
    "outputId": "da5a2006-2523-40cc-9853-fa7c061e3ad5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.0.203 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.196 ðŸš€ Python-3.8.8 torch-2.1.0+cu121 CUDA:0 (NVIDIA A100-SXM4-80GB, 81051MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=/scratch/ybt7qf/ds6050-group1-project/datasets/eurocitypersonsdataset.yaml, epochs=50, patience=50, batch=64, imgsz=640, save=True, save_period=-1, cache=False, device=[0], workers=8, project=DS6050_Pedestrian_ECP_YOLO, name=None, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=DS6050_Pedestrian_ECP_YOLO/train12\n",
      "Overriding model.yaml nc=80 with nc=12\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2120692  ultralytics.nn.modules.head.Detect           [12, [128, 256, 512]]         \n",
      "Model summary: 225 layers, 11140244 parameters, 11140228 gradients, 28.7 GFLOPs\n",
      "\n",
      "Transferred 349/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir DS6050_Pedestrian_ECP_YOLO/train12', view at http://localhost:6006/\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mybt7qf\u001b[0m (\u001b[33mds6050-pedestriandetection\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/sfs/qumulo/qhome/ybt7qf/ds6050-group1-project/wandb/run-20231031_154913-isr14j1c</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ds6050-pedestriandetection/DS6050_Pedestrian_ECP_YOLO/runs/isr14j1c' target=\"_blank\">tricky-ritual-14</a></strong> to <a href='https://wandb.ai/ds6050-pedestriandetection/DS6050_Pedestrian_ECP_YOLO' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ds6050-pedestriandetection/DS6050_Pedestrian_ECP_YOLO' target=\"_blank\">https://wandb.ai/ds6050-pedestriandetection/DS6050_Pedestrian_ECP_YOLO</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ds6050-pedestriandetection/DS6050_Pedestrian_ECP_YOLO/runs/isr14j1c' target=\"_blank\">https://wandb.ai/ds6050-pedestriandetection/DS6050_Pedestrian_ECP_YOLO/runs/isr14j1c</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "/home/ybt7qf/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /sfs/weka/scratch/ybt7qf/ds6050-group1-project/datasets/eurocitypersonsdataset/labels/train-resize... 28114 images, 2453 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28114/28114 [00:23<00:00, 1210.43it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /sfs/weka/scratch/ybt7qf/ds6050-group1-project/datasets/eurocitypersonsdataset/labels/train-resize.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /sfs/weka/scratch/ybt7qf/ds6050-group1-project/datasets/eurocitypersonsdataset/labels/val-resize... 5036 images, 388 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5036/5036 [00:04<00:00, 1165.75it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /sfs/weka/scratch/ybt7qf/ds6050-group1-project/datasets/eurocitypersonsdataset/labels/val-resize.cache\n",
      "Plotting labels to DS6050_Pedestrian_ECP_YOLO/train12/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mDS6050_Pedestrian_ECP_YOLO/train12\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       1/50      19.7G      1.881      2.141      1.227        187        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 440/440 [01:47<00:00,  4.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:20<00:00,  1.98it/s]\n",
      "                   all       5036      44769      0.678      0.111      0.112     0.0527\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/50      16.2G      1.776      1.486      1.154        185        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 440/440 [01:46<00:00,  4.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:19<00:00,  2.06it/s]\n",
      "                   all       5036      44769      0.366      0.109      0.104     0.0469\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/50      17.7G       1.86      1.566       1.19        132        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 440/440 [01:46<00:00,  4.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:30<00:00,  1.30it/s]\n",
      "                   all       5036      44769      0.207     0.0969     0.0737     0.0308\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/50      16.5G      1.895      1.596      1.211        106        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 440/440 [01:46<00:00,  4.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:19<00:00,  2.01it/s]\n",
      "                   all       5036      44769       0.34      0.107     0.0905     0.0354\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/50      17.3G      1.813      1.497      1.184        197        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 440/440 [01:45<00:00,  4.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:22<00:00,  1.79it/s]\n",
      "                   all       5036      44769      0.153      0.109     0.0969     0.0416\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/50      16.5G      1.768       1.45      1.161        492        640:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 191/440 [00:46<01:00,  4.14it/s]"
     ]
    }
   ],
   "source": [
    "model = YOLO(\"yolov8s.pt\")\n",
    "model.train(project=\"DS6050_Pedestrian_ECP_YOLO\",\n",
    "            data=\"/scratch/ybt7qf/ds6050-group1-project/datasets/eurocitypersonsdataset.yaml\",\n",
    "            epochs=50, \n",
    "            verbose=True, \n",
    "            batch=64,\n",
    "            device=[0])\n",
    "\n",
    "# finish the wandb run, necessary in notebooks\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5213cdd4-8e12-4a1d-b90c-0281ed1e5246",
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# metrics = model.val()  # evaluate model performance on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = YOLO('')  # load a custom trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = YOLO('last.pt')\n",
    "# model.train(\n",
    "#     devices=[4, 5, 6],\n",
    "#     resume=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = YOLO(\"last.pt\")\n",
    "# model.train(project=\"DS6050_Pedestrian_ECP_YOLO\",\n",
    "#             data=\"/scratch/ybt7qf/ds6050-group1-project/datasets/eurocitypersonsdataset.yaml\",\n",
    "#             epochs=50, \n",
    "#             verbose=True, \n",
    "#             batch=64,\n",
    "#             device=[0])\n",
    "\n",
    "# # finish the wandb run, necessary in notebooks\n",
    "# wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
